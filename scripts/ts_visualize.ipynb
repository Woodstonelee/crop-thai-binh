{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize the time series of 30-m fused images from Landsat and MODIS\n",
    "\n",
    "## A contract project of Asia Development Bank\n",
    "\n",
    "### Contractor:\n",
    "* Kaiyu Guan\n",
    "* Zhan Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import glob\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal, gdal_array, osr, ogr\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "dpi = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True) # run at the start of every ipython notebook to use plotly.offline\n",
    "                     # this injects the plotly.js source files into the notebook\n",
    "import plotly.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%writefile ./geo_ts.py\n",
    "def read_pixel_GDAL(filename, x, y):\n",
    "    \"\"\" Reads in a pixel of data from an images using GDAL\n",
    "    Args:\n",
    "      filename (str): filename to read from\n",
    "      x (int): column\n",
    "      y (int): row\n",
    "    Returns:\n",
    "      np.ndarray: 1D array (nband) containing the pixel data\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "    if ds is None:\n",
    "        sys.stderr.write(\"Failed to open the file {0:s}\\n\".format(filename))\n",
    "        return None\n",
    "    \n",
    "    dtype = gdal_array.GDALTypeCodeToNumericTypeCode(\n",
    "        ds.GetRasterBand(1).DataType)\n",
    "\n",
    "    dat = np.empty(ds.RasterCount, dtype=dtype)\n",
    "    for i in range(ds.RasterCount):\n",
    "        dat[i] = ds.GetRasterBand(i + 1).ReadAsArray(x, y, 1, 1)\n",
    "        \n",
    "    ds = None\n",
    "\n",
    "    return dat\n",
    "\n",
    "# get time series and doy from a list of single-band image files\n",
    "def get_ts_from_imgs(imgfiles, img_points):\n",
    "    n = len(imgfiles)\n",
    "    ts_data = {k:np.zeros(n) for k in img_points.keys()}\n",
    "    for k in img_points.keys():\n",
    "        for n, imgf in enumerate(imgfiles):\n",
    "            ts_data[k][n] = read_pixel_GDAL(imgf, img_points[k][0], img_points[k][1])    \n",
    "    # doy = np.array([int(os.path.basename(imgf).split(\".\")[2][4:]) for imgf in imgfiles])\n",
    "    fnames = [os.path.basename(imgf) for imgf in imgfiles]\n",
    "    return fnames, ts_data\n",
    "\n",
    "def get_raster_meta_GDAL(filename, band_idx=1):\n",
    "    \"\"\"Retrieve the meta information of an image using GDAL\n",
    "    Args:\n",
    "      filename: str\n",
    "          file name to read from\n",
    "      band_idx: int, default 1\n",
    "          index to the band to retrieve meta data for, with the first being 1.\n",
    "    Returns:\n",
    "      meta: dict\n",
    "          returned meta data records about the image\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "    if ds is None:\n",
    "        sys.stderr.write(\"Failed to open the file {0:s}\\n\".format(filename))\n",
    "        return None\n",
    "    \n",
    "    dtype = gdal_array.GDALTypeCodeToNumericTypeCode(\n",
    "        ds.GetRasterBand(1).DataType)\n",
    "    \n",
    "    band = ds.GetRasterBand(band_idx)\n",
    "    nodata = band.GetNoDataValue()\n",
    "    \n",
    "    ncol = ds.RasterXSize\n",
    "    nrow = ds.RasterYSize\n",
    "    \n",
    "    geo_trans = ds.GetGeoTransform()\n",
    "    \n",
    "    return {\"DataType\":dtype, \"NoDataValue\":nodata, \"RasterXSize\":ncol, \"RasterYSize\":nrow, \\\n",
    "            \"GeoTransform\":geo_trans}\n",
    "\n",
    "def proj2Pixel(geoMatrix, x, y):\n",
    "    \"\"\"\n",
    "    Uses a gdal geomatrix (gdal.GetGeoTransform()) to calculate\n",
    "    the pixel location, with 0 being the first pixel, of \n",
    "    a geospatial coordinate in the projection system.\n",
    "    \"\"\"\n",
    "    ulX = geoMatrix[0]\n",
    "    ulY = geoMatrix[3]\n",
    "    xDist = geoMatrix[1]\n",
    "    yDist = geoMatrix[5]\n",
    "    rtnX = geoMatrix[2]\n",
    "    rtnY = geoMatrix[4]\n",
    "    sample = int((x - ulX) / xDist)\n",
    "    line = int((y - ulY) / yDist)\n",
    "    return (sample, line)\n",
    "\n",
    "def pixel2Proj(geoMatrix, sample, line):\n",
    "    \"\"\"\n",
    "    Covnert pixel location (sample, line), \n",
    "    with 0 being the first pixel, to the \n",
    "    geospatial coordinates in the projection system, \n",
    "    with (x, y) being the UL corner of the pixel.\n",
    "    \"\"\"\n",
    "    ulX = geoMatrix[0]\n",
    "    ulY = geoMatrix[3]\n",
    "    xDist = geoMatrix[1]\n",
    "    yDist = geoMatrix[5]\n",
    "    rtnX = geoMatrix[2]\n",
    "    rtnY = geoMatrix[4]\n",
    "    x = sample * xDist + ulX\n",
    "    y = line * yDist + ulY\n",
    "    return (x, y)\n",
    "\n",
    "def geo2Proj(filename, lon, lat):\n",
    "    \"\"\"\n",
    "    Convert geographic coordinates to projected coordinates \n",
    "    given the input raster file\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "    out_sr = osr.SpatialReference()\n",
    "    out_sr.ImportFromWkt(ds.GetProjectionRef())\n",
    "    in_sr = out_sr.CloneGeogCS()\n",
    "    coord_trans = osr.CoordinateTransformation(in_sr, out_sr)\n",
    "    return coord_trans.TransformPoint(lon, lat)[0:2]\n",
    "\n",
    "def proj2Geo(filename, x, y):\n",
    "    \"\"\"\n",
    "    Convert projected coordinates to geographic coordinates\n",
    "    given the input raster file    \n",
    "    \"\"\"\n",
    "    ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "    in_sr = osr.SpatialReference()\n",
    "    in_sr.ImportFromWkt(ds.GetProjectionRef())\n",
    "    out_sr = in_sr.CloneGeogCS()\n",
    "    coord_trans = osr.CoordinateTransformation(in_sr, out_sr)\n",
    "    return coord_trans.TransformPoint(x, y)[0:2]\n",
    "\n",
    "def geo2Pixel(filename, lon, lat):\n",
    "    \"\"\"\n",
    "    Convert geographic coordinates to image coordinates \n",
    "    given the input raster file\n",
    "    \"\"\"\n",
    "    ds_meta = get_raster_meta_GDAL(filename)\n",
    "    proj_coord = geo2Proj(filename, lon, lat)\n",
    "    return proj2Pixel(ds_meta[\"GeoTransform\"], proj_coord[0], proj_coord[1])\n",
    "\n",
    "def pixel2Geo(filename, sample, line):\n",
    "    \"\"\"\n",
    "    Convert the image coordinates to geographic coordinates given the input raster file.\n",
    "    \"\"\"\n",
    "    ds_meta = get_raster_meta_GDAL(filename)\n",
    "    proj_coord = pixel2Proj(ds_meta[\"GeoTransform\"], sample, line)\n",
    "    return proj2Geo(filename, proj_coord[0], proj_coord[1])\n",
    "\n",
    "def plot_ts(doy_list, ts_data_list, point_coords, \\\n",
    "            style_list=None, plot_kw_dict_list=None, xlabel=\"DOY\", ylabel=\"Value\", \\\n",
    "            figsize=(8, 4), use_plotly=False, select_doy=None, nodata=-9999):\n",
    "    \n",
    "    valid_flag_list = [{k:np.logical_and(ts_data[k] != nodata, ts_data[k] > 0) for k in ts_data.keys()} for ts_data in ts_data_list]\n",
    "    select_keys_list = [{k:np.sum(valid_flag[k])>0 for k in valid_flag.keys()} for valid_flag in valid_flag_list]\n",
    "    ymin = np.nanmin([np.nanmin([np.min(ts_data[k][valid_flag[k]]) if select_keys[k] else np.nan for k in ts_data.keys()]) \\\n",
    "                   for ts_data, valid_flag, select_keys in itertools.izip(ts_data_list, valid_flag_list, select_keys_list)])\n",
    "    ymax = np.nanmax([np.nanmax([np.max(ts_data[k][valid_flag[k]]) if select_keys[k] else np.nan for k in ts_data.keys()]) \\\n",
    "                   for ts_data, valid_flag, select_keys in itertools.izip(ts_data_list, valid_flag_list, select_keys_list)])\n",
    "    \n",
    "    if ymin is np.nan or ymax is np.nan:\n",
    "        warnings.warn(\"No valid values in all the given time series\")\n",
    "        return None\n",
    "    \n",
    "    colors = mpl.colors.cnames.keys()[len(doy_list)]\n",
    "    \n",
    "    for point_key in point_coords.keys():\n",
    "        fig, ax = plt.subplots(num=point_key, figsize=figsize)\n",
    "        for n, (doy, ts_data) in enumerate(itertools.izip(doy_list, ts_data_list)):\n",
    "            if not select_keys_list[n][point_key]:\n",
    "                continue\n",
    "            flag = valid_flag_list[n][point_key]\n",
    "            if style_list is not None:\n",
    "                if plot_kw_dict_list is not None:\n",
    "                    ax.plot(doy[flag], ts_data[point_key][flag], style_list[n], **plot_kw_dict_list[n])\n",
    "                else:\n",
    "                    ax.plot(doy[flag], ts_data[point_key][flag], style_list[n])\n",
    "            else:\n",
    "                if plot_kw_dict_list is not None:\n",
    "                    ax.plot(doy[flag], ts_data[point_key][flag], **plot_kw_dict_list[n])\n",
    "                else:\n",
    "                    ax.plot(doy[flag], ts_data[point_key][flag])\n",
    "\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_xlim(-1.5, 366.5)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(\"{0:s}, coordinates: ({1:.6f}, {2:.6f})\".format(point_key, point_coords[point_key][0], point_coords[point_key][1]))    \n",
    "\n",
    "        if use_plotly:\n",
    "            plotly_fig = plotly.tools.mpl_to_plotly(fig)\n",
    "            plotly_fig['layout']['showlegend'] = True\n",
    "            plotly_fig['layout']['legend'] = dict(orientation=\"h\")\n",
    "            iplot(plotly_fig)\n",
    "        else:        \n",
    "            plt.figure(point_key)\n",
    "            if select_doy is not None:\n",
    "                for d in select_doy:\n",
    "                    ax.plot(np.array([d, d]), ax.get_ylim(), '--k')\n",
    "            ax.legend(ncol=2, loc='upper center', bbox_to_anchor=(0.5, -0.15))        \n",
    "            plt.savefig(\"../figures/ts_{0:s}_{1:s}.png\".format(ylabel.lower(), point_key.replace(\" \", \"_\").lower()), \\\n",
    "                        dpi = dpi, bbox_inches=\"tight\", pad_inches=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time series file by fusion of Landsat and MODIS BEFORE TIMESAT smoothing\n",
    "ts_ndvi_fused_file = \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-fusion-ts/predicted_NDVI\"\n",
    "\n",
    "# time series file by fusion of Landsat and MODIS AFTER TIMESAT smoothing\n",
    "ts_ndvi_timesat_file = \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-fusion-ts/fit_NDVI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # the lat and lon of points of which time series to be visualized\n",
    "# geo_points = { \\\n",
    "#               \"Point 1\":(106.378046, 20.429023), \\\n",
    "#               \"Point 2\":(106.506207, 20.461707), \\\n",
    "#               \"Point 3\":(106.46351961, 20.48002966), \\\n",
    "#               \"Point 4\":(106.46235387, 20.47841337) \\\n",
    "#              }\n",
    "# geo_points = { \\\n",
    "#               \"SGveg-LSATcrop\": (106.07962212, 20.61375514), \\\n",
    "#               \"SGveg-LSATbarren\": (106.08106149, 20.61374614), \\\n",
    "#               \"SGcrop-LSATcrop\": (106.31273800, 20.57257159)}\n",
    "\n",
    "# # convert the geographic coordinates of given points to image coordinates\n",
    "# img_points = {pk:geo2Pixel(ts_ndvi_fused_file, geo_points[pk][0], geo_points[pk][1]) for pk in geo_points.keys()}\n",
    "# proj_points = {pk:geo2Proj(ts_ndvi_fused_file, geo_points[pk][0], geo_points[pk][1]) for pk in geo_points.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # randomly select several points to visualize\n",
    "# npts = 4\n",
    "# ts_ndvi_fused_meta = get_raster_meta_GDAL(ts_ndvi_fused_file)\n",
    "# img_points = {\"Point {0:d}\".format(i+1):(np.random.randint(0, ts_ndvi_fused_meta[\"RasterXSize\"]), \\\n",
    "#                                        np.random.randint(0, ts_ndvi_fused_meta[\"RasterYSize\"])) for i in range(npts)}\n",
    "\n",
    "# # the sample (column) and line (row) of the points in the image\n",
    "# img_points = { \\\n",
    "#               \"Point 1\":(1094, 1192), \\\n",
    "#               \"Point 2\":(1460, 1475) \\\n",
    "#              }\n",
    "\n",
    "# # Convert image coordinates to geographic and projected coordinates\n",
    "# geo_points = {k:pixel2Geo(ts_ndvi_fused_file, img_points[k][0], img_points[k][1]) for k in img_points.keys()}\n",
    "# proj_points = {k:pixel2Proj(get_raster_meta_GDAL(ts_ndvi_fused_file)[\"GeoTransform\"], img_points[k][0], img_points[k][1]) for k in img_points.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select points from specific classes from the classification map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "['croplands', 'barren', 'urban_and_built_up', 'water_bodies', 'wetlands', 'natural_terrestrial_veg']\n",
      "[1901126  105711 1204497  729353   47654    4617]\n",
      "[ 0.47611971  0.02647436  0.30165531  0.18265982  0.01193451  0.00115629]\n"
     ]
    }
   ],
   "source": [
    "# Give classification image files\n",
    "cls_img_file_list = [\\\n",
    "                     \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-cls/vietnam_thai_bin_cls_rf_lsat_scenes.img\", \\\n",
    "                     \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-cls/vietnam_thai_bin_cls_rf_sg_ndvi.img\"]\n",
    "\n",
    "cls_img_label_list = [\\\n",
    "                      \"SR_3_Scenes\", \\\n",
    "                      \"NDVI_TS_SG\"]\n",
    "\n",
    "cls_rnd_sample_shapefile = \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-cls/vietnam_thai_bin_cls_rf_lsat_scenes_rnd_samples.shp\"\n",
    "\n",
    "# read classification map\n",
    "from classify_image import ImageClassifier\n",
    "ic = ImageClassifier()\n",
    "cls_map_profile_list = [ic.getRasterProfile(cif) for cif in cls_img_file_list]\n",
    "\n",
    "ncls_list = [int(cls_map_profile['Metadata']['ENVI']['classes']) - 1 for cls_map_profile in cls_map_profile_list]\n",
    "no_data = 0\n",
    "cls_map_list = [ic.readRaster(cif)[0][0] for cif in cls_img_file_list]\n",
    "cls_map_masked_list = [np.ma.masked_equal(cm, no_data) for cm in cls_map_list]\n",
    "\n",
    "# Designate the map to use\n",
    "n = 0\n",
    "cls_map = cls_map_list[n]\n",
    "cls_map_profile = cls_map_profile_list[n]\n",
    "no_data = 0\n",
    "\n",
    "cls_code = np.arange(int(cls_map_profile['Metadata']['ENVI']['classes'])-1, dtype=np.int8)+1\n",
    "cls_name = cls_map_profile['Metadata']['ENVI']['class_names'].strip('{}').split(',')[1:]\n",
    "cls_name = [cn.strip() for cn in cls_name]\n",
    "cls_npix = np.array([np.sum(cls_map==cls) for cls in cls_code])\n",
    "total_npix = np.sum(cls_npix)\n",
    "cls_w = cls_npix / float(total_npix)\n",
    "print cls_code\n",
    "print cls_name\n",
    "print cls_npix\n",
    "print cls_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read reference data\n",
    "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "data_src = driver.Open(cls_rnd_sample_shapefile, 0)\n",
    "layer = data_src.GetLayer()\n",
    "\n",
    "npts = layer.GetFeatureCount()\n",
    "layer_def = layer.GetLayerDefn()\n",
    "nfields = layer_def.GetFieldCount()\n",
    "# get name of fields\n",
    "field_names = [layer_def.GetFieldDefn(i).GetName() for i in range(nfields)]\n",
    "# set up a pandas dataframe to read the feature attributes\n",
    "cls_ref_df = pd.DataFrame(np.zeros((npts, nfields)), columns=field_names)\n",
    "\n",
    "for i, feature in enumerate(layer):\n",
    "    tmp_list = [feature.GetField(fd) for fd in field_names]\n",
    "    cls_ref_df.iloc[i, :] = np.array([0 if item is None else np.float(item) for item in tmp_list])\n",
    "\n",
    "data_src.Destroy()\n",
    "\n",
    "# Fill the secondary reference labels\n",
    "tmp_flag = cls_ref_df['SecRefCode'] == 0\n",
    "cls_ref_df.loc[tmp_flag, 'SecRefCode'] = cls_ref_df.loc[tmp_flag, 'PriRefCode']\n",
    "\n",
    "# Get the classification labels\n",
    "cls_ref_df['ClsCode'] = cls_map[cls_ref_df['Line'].astype(int), cls_ref_df['Sample'].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_points = OrderedDict()\n",
    "\n",
    "# Randomly select several pixels with correct cropland classification and \n",
    "# several with wrong cropland classification\n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(np.logical_and(cls_ref_df['ClsCode']==1, cls_ref_df['PriRefCode']==1))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))\n",
    "        \n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(np.logical_and(cls_ref_df['ClsCode']==1, cls_ref_df['PriRefCode']!=1))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))\n",
    "        \n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(np.logical_and(cls_ref_df['ClsCode']!=1, cls_ref_df['PriRefCode']==1))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))\n",
    "        \n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(reduce(np.logical_and, (cls_ref_df['ClsCode']!=1, cls_ref_df['PriRefCode']!=1, cls_ref_df['ClsCode']==cls_ref_df['PriRefCode'])))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert image coordinates to geographic and projected coordinates\n",
    "geo_points = OrderedDict([(k, pixel2Geo(ts_ndvi_fused_file, img_points[k][0]+0.5, img_points[k][1]+0.5)) for k in img_points.keys()])\n",
    "proj_points = OrderedDict([(k, pixel2Proj(get_raster_meta_GDAL(ts_ndvi_fused_file)[\"GeoTransform\"], img_points[k][0]+0.5, img_points[k][1]+0.5)) for k in img_points.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Cls(1)-Ref(1)-Pts01', (735, 591)), ('Cls(1)-Ref(1)-Pts02', (1586, 123)), ('Cls(1)-Ref(1)-Pts03', (328, 1505)), ('Cls(1)-Ref(1)-Pts04', (1284, 897)), ('Cls(1)-Ref(1)-Pts05', (1581, 216)), ('Cls(1)-Ref(1)-Pts06', (968, 81)), ('Cls(1)-Ref(3)-Pts01', (1601, 1568)), ('Cls(1)-Ref(4)-Pts02', (799, 1670)), ('Cls(1)-Ref(2)-Pts03', (244, 93)), ('Cls(1)-Ref(6)-Pts04', (565, 623)), ('Cls(1)-Ref(6)-Pts05', (937, 555)), ('Cls(1)-Ref(6)-Pts06', (1267, 1225)), ('Cls(6)-Ref(1)-Pts01', (1056, 351)), ('Cls(4)-Ref(1)-Pts02', (430, 329)), ('Cls(3)-Ref(1)-Pts03', (712, 1296)), ('Cls(3)-Ref(1)-Pts04', (556, 1240)), ('Cls(3)-Ref(1)-Pts05', (610, 1227)), ('Cls(3)-Ref(1)-Pts06', (690, 488)), ('Cls(2)-Ref(2)-Pts01', (1650, 1093)), ('Cls(2)-Ref(2)-Pts02', (1867, 1455)), ('Cls(2)-Ref(2)-Pts03', (1223, 1949)), ('Cls(3)-Ref(3)-Pts04', (928, 1983)), ('Cls(3)-Ref(3)-Pts05', (876, 1300)), ('Cls(2)-Ref(2)-Pts06', (829, 136))])\n",
      "OrderedDict([('Cls(1)-Ref(1)-Pts01', (106.2759246545955, 20.59276767410469)), ('Cls(1)-Ref(1)-Pts02', (106.52210248632723, 20.71760829916048)), ('Cls(1)-Ref(1)-Pts03', (106.15692359058261, 20.345870238462922)), ('Cls(1)-Ref(1)-Pts04', (106.43315531113319, 20.508604473020636)), ('Cls(1)-Ref(1)-Pts05', (106.52041102825429, 20.692419624925048)), ('Cls(1)-Ref(1)-Pts06', (106.34419952916434, 20.73047267654823)), ('Cls(1)-Ref(3)-Pts01', (106.52254478294435, 20.3259922638821)), ('Cls(1)-Ref(4)-Pts02', (106.29189814926646, 20.300202953869075)), ('Cls(1)-Ref(2)-Pts03', (106.13560643214245, 20.728723709583186)), ('Cls(1)-Ref(6)-Pts04', (106.22692642828387, 20.584449045275182)), ('Cls(1)-Ref(6)-Pts05', (106.33414717223326, 20.602085343369012)), ('Cls(1)-Ref(6)-Pts06', (106.42744351524246, 20.419756222184606)), ('Cls(6)-Ref(1)-Pts01', (106.36889235933613, 20.657102363086494)), ('Cls(4)-Ref(1)-Pts02', (106.18869107831124, 20.664400868304273)), ('Cls(3)-Ref(1)-Pts03', (106.26773257840043, 20.401748325917062)), ('Cls(3)-Ref(1)-Pts04', (106.2230084995772, 20.417246176215247)), ('Cls(3)-Ref(1)-Pts05', (106.23856120595134, 20.420659798898413)), ('Cls(3)-Ref(1)-Pts06', (106.26320306732298, 20.620777342258087)), ('Cls(2)-Ref(2)-Pts01', (106.53789825306981, 20.454589611086384)), ('Cls(2)-Ref(2)-Pts02', (106.5992765689622, 20.35593123320492)), ('Cls(2)-Ref(2)-Pts03', (106.41301169948113, 20.2236497977262)), ('Cls(3)-Ref(3)-Pts04', (106.32823356083512, 20.215096391512834)), ('Cls(3)-Ref(3)-Pts05', (106.31486605098696, 20.400314999705316)), ('Cls(2)-Ref(2)-Pts06', (106.30403045927969, 20.715875481024113))])\n",
      "OrderedDict([('Cls(1)-Ref(1)-Pts01', (632970.0, 2277600.0)), ('Cls(1)-Ref(1)-Pts02', (658500.0, 2291640.0)), ('Cls(1)-Ref(1)-Pts03', (620760.0, 2250180.0)), ('Cls(1)-Ref(1)-Pts04', (649440.0, 2268420.0)), ('Cls(1)-Ref(1)-Pts05', (658350.0, 2288850.0)), ('Cls(1)-Ref(1)-Pts06', (639960.0, 2292900.0)), ('Cls(1)-Ref(3)-Pts01', (658950.0, 2248290.0)), ('Cls(1)-Ref(4)-Pts02', (634890.0, 2245230.0)), ('Cls(1)-Ref(2)-Pts03', (618240.0, 2292540.0)), ('Cls(1)-Ref(6)-Pts04', (627870.0, 2276640.0)), ('Cls(1)-Ref(6)-Pts05', (639030.0, 2278680.0)), ('Cls(1)-Ref(6)-Pts06', (648930.0, 2258580.0)), ('Cls(6)-Ref(1)-Pts01', (642600.0, 2284800.0)), ('Cls(4)-Ref(1)-Pts02', (623820.0, 2285460.0)), ('Cls(3)-Ref(1)-Pts03', (632280.0, 2256450.0)), ('Cls(3)-Ref(1)-Pts04', (627600.0, 2258130.0)), ('Cls(3)-Ref(1)-Pts05', (629220.0, 2258520.0)), ('Cls(3)-Ref(1)-Pts06', (631620.0, 2280690.0)), ('Cls(2)-Ref(2)-Pts01', (660420.0, 2262540.0)), ('Cls(2)-Ref(2)-Pts02', (666930.0, 2251680.0)), ('Cls(2)-Ref(2)-Pts03', (647610.0, 2236860.0)), ('Cls(3)-Ref(3)-Pts04', (638760.0, 2235840.0)), ('Cls(3)-Ref(3)-Pts05', (637200.0, 2256330.0)), ('Cls(2)-Ref(2)-Pts06', (635790.0, 2291250.0))])\n"
     ]
    }
   ],
   "source": [
    "# show the points to be visualized\n",
    "print img_points\n",
    "print geo_points\n",
    "print proj_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series from stacked STARFM+Landsat and TIMESAT DL fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_ndvi_fused_data = { k:read_pixel_GDAL(ts_ndvi_fused_file, img_points[k][0], img_points[k][1]) for k in img_points.keys()}\n",
    "ts_ndvi_fused_doy = np.arange(len(ts_ndvi_fused_data[ts_ndvi_fused_data.keys()[0]]))+1\n",
    "# sort the data points according to doy\n",
    "sort_ind = np.argsort(ts_ndvi_fused_doy)\n",
    "ts_ndvi_fused_data = {k:ts_ndvi_fused_data[k][sort_ind] for k in ts_ndvi_fused_data.keys()}\n",
    "ts_ndvi_fused_doy = ts_ndvi_fused_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_ndvi_timesat_data = { k:read_pixel_GDAL(ts_ndvi_timesat_file, img_points[k][0], img_points[k][1]) for k in img_points.keys()}\n",
    "ts_ndvi_timesat_doy = np.arange(len(ts_ndvi_timesat_data[ts_ndvi_timesat_data.keys()[0]]))+1\n",
    "# sort the data points according to doy\n",
    "sort_ind = np.argsort(ts_ndvi_timesat_doy)\n",
    "ts_ndvi_timesat_data = {k:ts_ndvi_timesat_data[k][sort_ind] for k in ts_ndvi_timesat_data.keys()}\n",
    "ts_ndvi_timesat_doy = ts_ndvi_timesat_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_ndvi_fused_meta = get_raster_meta_GDAL(ts_ndvi_fused_file)\n",
    "# get the nodata value of the given image\n",
    "if ts_ndvi_fused_meta[\"NoDataValue\"] is None:\n",
    "    nodata = -9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Selected DOY for image visualization\n",
    "    * Around second peak: 242, 245\n",
    "    * Around the trough: 186, 192\n",
    "    * Last day in the year: 365, 365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series from STARFM fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# red_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-starfm/Vietnam/plndsr_250.126046.2015*.red.bin\")\n",
    "# nir_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-starfm/Vietnam/plndsr_250.126046.2015*.nir.bin\")\n",
    "# ndvi_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-starfm/Vietnam/plndsr_250.126046.2015*.ndvi.bin\")\n",
    "\n",
    "# fnames, red_ts_data = get_ts_from_imgs(red_imgfiles, img_points)\n",
    "# red_doy = np.array([int(imgf.split(\".\")[2][4:]) for imgf in fnames])\n",
    "# # sort the data points according to doy\n",
    "# sort_ind = np.argsort(red_doy)\n",
    "# red_ts_data = {k:red_ts_data[k][sort_ind] for k in red_ts_data.keys()}\n",
    "# red_doy = red_doy[sort_ind]\n",
    "\n",
    "# fnames, nir_ts_data = get_ts_from_imgs(nir_imgfiles, img_points)\n",
    "# nir_doy = np.array([int(imgf.split(\".\")[2][4:]) for imgf in fnames])\n",
    "# # sort the data points according to doy\n",
    "# sort_ind = np.argsort(nir_doy)\n",
    "# nir_ts_data = {k:nir_ts_data[k][sort_ind] for k in nir_ts_data.keys()}\n",
    "# nir_doy = nir_doy[sort_ind]\n",
    "\n",
    "# fnames, ndvi_ts_data = get_ts_from_imgs(ndvi_imgfiles, img_points)\n",
    "# ndvi_doy = np.array([int(imgf.split(\".\")[2][4:]) for imgf in fnames])\n",
    "# # sort the data points according to doy\n",
    "# sort_ind = np.argsort(ndvi_doy)\n",
    "# ndvi_ts_data = {k:ndvi_ts_data[k][sort_ind] for k in ndvi_ts_data.keys()}\n",
    "# ndvi_doy = ndvi_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markers = mpl.markers.MarkerStyle().markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_ts([red_doy, nir_doy], [red_ts_data, nir_ts_data], geo_points, \\\n",
    "#         style_list=['.r', '.b'], \\\n",
    "#         plot_kw_dict_list=[dict(label=\"Red\"), dict(label=\"NIR\")], \\\n",
    "#         use_plotly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_ts([np.arange(len(ts_ndvi_fused_data[ts_ndvi_fused_data.keys()[0]]))+1, ndvi_doy], [ts_ndvi_fused_data, ndvi_ts_data], geo_points, \\\n",
    "#         style_list=['.r', '.g'], \\\n",
    "#         plot_kw_dict_list=[dict(label=\"NDVI Predicted\"), dict(label=\"NDVI STARFM\")], \\\n",
    "#         use_plotly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series from TIMESAT SG fitting to STARFM+Landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitsg_ndvi_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-ts-sg/fitSG_NDVI_126046.2015[0-9][0-9][0-9]\")\n",
    "\n",
    "fnames, sg_ndvi_ts_data = get_ts_from_imgs(fitsg_ndvi_imgfiles, img_points)\n",
    "sg_ndvi_doy = np.array([int(imgf.split(\".\")[1][4:]) for imgf in fnames])\n",
    "# sort the data points according to doy\n",
    "sort_ind = np.argsort(sg_ndvi_doy)\n",
    "sg_ndvi_ts_data = {k:sg_ndvi_ts_data[k][sort_ind] for k in sg_ndvi_ts_data.keys()}\n",
    "sg_ndvi_doy = sg_ndvi_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ts([ts_ndvi_fused_doy, ts_ndvi_timesat_doy, sg_ndvi_doy], \\\n",
    "        [ts_ndvi_fused_data, ts_ndvi_timesat_data, sg_ndvi_ts_data], geo_points, \\\n",
    "        style_list=['.r', '-b', '-k'], \\\n",
    "        plot_kw_dict_list=[dict(label=\"NDVI Predicted (fused + LC8)\"), dict(label=\"NDVI TIMESAT Double Logistic\"), dict(label=\"NDVI TIMESAT SG\")], \\\n",
    "        use_plotly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
