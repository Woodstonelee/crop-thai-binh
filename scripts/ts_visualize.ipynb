{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize the time series of 30-m fused images from Landsat and MODIS\n",
    "\n",
    "## A contract project of Asia Development Bank\n",
    "\n",
    "### Contractor:\n",
    "* Kaiyu Guan\n",
    "* Zhan Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import glob\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal, gdal_array, osr, ogr\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "dpi = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True) # run at the start of every ipython notebook to use plotly.offline\n",
    "                     # this injects the plotly.js source files into the notebook\n",
    "import plotly.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time series file by fusion of Landsat and MODIS BEFORE TIMESAT smoothing\n",
    "ts_ndvi_fused_file = \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-fusion-ts/predicted_NDVI\"\n",
    "\n",
    "# time series file by fusion of Landsat and MODIS AFTER TIMESAT smoothing\n",
    "ts_ndvi_timesat_file = \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-fusion-ts/fit_NDVI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # the lat and lon of points of which time series to be visualized\n",
    "# geo_points = { \\\n",
    "#               \"Point 1\":(106.378046, 20.429023), \\\n",
    "#               \"Point 2\":(106.506207, 20.461707), \\\n",
    "#               \"Point 3\":(106.46351961, 20.48002966), \\\n",
    "#               \"Point 4\":(106.46235387, 20.47841337) \\\n",
    "#              }\n",
    "# geo_points = { \\\n",
    "#               \"SGveg-LSATcrop\": (106.07962212, 20.61375514), \\\n",
    "#               \"SGveg-LSATbarren\": (106.08106149, 20.61374614), \\\n",
    "#               \"SGcrop-LSATcrop\": (106.31273800, 20.57257159)}\n",
    "\n",
    "# # convert the geographic coordinates of given points to image coordinates\n",
    "# img_points = {pk:geo2Pixel(ts_ndvi_fused_file, geo_points[pk][0], geo_points[pk][1]) for pk in geo_points.keys()}\n",
    "# proj_points = {pk:geo2Proj(ts_ndvi_fused_file, geo_points[pk][0], geo_points[pk][1]) for pk in geo_points.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # randomly select several points to visualize\n",
    "# npts = 4\n",
    "# ts_ndvi_fused_meta = get_raster_meta_GDAL(ts_ndvi_fused_file)\n",
    "# img_points = {\"Point {0:d}\".format(i+1):(np.random.randint(0, ts_ndvi_fused_meta[\"RasterXSize\"]), \\\n",
    "#                                        np.random.randint(0, ts_ndvi_fused_meta[\"RasterYSize\"])) for i in range(npts)}\n",
    "\n",
    "# # the sample (column) and line (row) of the points in the image\n",
    "# img_points = { \\\n",
    "#               \"Point 1\":(1094, 1192), \\\n",
    "#               \"Point 2\":(1460, 1475) \\\n",
    "#              }\n",
    "\n",
    "# # Convert image coordinates to geographic and projected coordinates\n",
    "# geo_points = {k:pixel2Geo(ts_ndvi_fused_file, img_points[k][0], img_points[k][1]) for k in img_points.keys()}\n",
    "# proj_points = {k:pixel2Proj(get_raster_meta_GDAL(ts_ndvi_fused_file)[\"GeoTransform\"], img_points[k][0], img_points[k][1]) for k in img_points.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select points from specific classes from the classification map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "['croplands', 'barren', 'urban_and_built_up', 'water_bodies', 'wetlands', 'natural_terrestrial_veg']\n",
      "[1901126  105711 1204497  729353   47654    4617]\n",
      "[ 0.47611971  0.02647436  0.30165531  0.18265982  0.01193451  0.00115629]\n"
     ]
    }
   ],
   "source": [
    "# Give classification image files\n",
    "cls_img_file_list = [\\\n",
    "                     \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-cls/vietnam_thai_bin_cls_rf_lsat_scenes.img\", \\\n",
    "                     \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-cls/vietnam_thai_bin_cls_rf_sg_ndvi.img\"]\n",
    "\n",
    "cls_img_label_list = [\\\n",
    "                      \"SR_3_Scenes\", \\\n",
    "                      \"NDVI_TS_SG\"]\n",
    "\n",
    "cls_rnd_sample_shapefile = \"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-cls/vietnam_thai_bin_cls_rf_lsat_scenes_rnd_samples.shp\"\n",
    "\n",
    "# read classification map\n",
    "from classify_image import ImageClassifier\n",
    "ic = ImageClassifier()\n",
    "cls_map_profile_list = [ic.getRasterProfile(cif) for cif in cls_img_file_list]\n",
    "\n",
    "ncls_list = [int(cls_map_profile['Metadata']['ENVI']['classes']) - 1 for cls_map_profile in cls_map_profile_list]\n",
    "no_data = 0\n",
    "cls_map_list = [ic.readRaster(cif)[0][0] for cif in cls_img_file_list]\n",
    "cls_map_masked_list = [np.ma.masked_equal(cm, no_data) for cm in cls_map_list]\n",
    "\n",
    "# Designate the map to use\n",
    "n = 0\n",
    "cls_map = cls_map_list[n]\n",
    "cls_map_profile = cls_map_profile_list[n]\n",
    "no_data = 0\n",
    "\n",
    "cls_code = np.arange(int(cls_map_profile['Metadata']['ENVI']['classes'])-1, dtype=np.int8)+1\n",
    "cls_name = cls_map_profile['Metadata']['ENVI']['class_names'].strip('{}').split(',')[1:]\n",
    "cls_name = [cn.strip() for cn in cls_name]\n",
    "cls_npix = np.array([np.sum(cls_map==cls) for cls in cls_code])\n",
    "total_npix = np.sum(cls_npix)\n",
    "cls_w = cls_npix / float(total_npix)\n",
    "print cls_code\n",
    "print cls_name\n",
    "print cls_npix\n",
    "print cls_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read reference data\n",
    "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "data_src = driver.Open(cls_rnd_sample_shapefile, 0)\n",
    "layer = data_src.GetLayer()\n",
    "\n",
    "npts = layer.GetFeatureCount()\n",
    "layer_def = layer.GetLayerDefn()\n",
    "nfields = layer_def.GetFieldCount()\n",
    "# get name of fields\n",
    "field_names = [layer_def.GetFieldDefn(i).GetName() for i in range(nfields)]\n",
    "# set up a pandas dataframe to read the feature attributes\n",
    "cls_ref_df = pd.DataFrame(np.zeros((npts, nfields)), columns=field_names)\n",
    "\n",
    "for i, feature in enumerate(layer):\n",
    "    tmp_list = [feature.GetField(fd) for fd in field_names]\n",
    "    cls_ref_df.iloc[i, :] = np.array([0 if item is None else np.float(item) for item in tmp_list])\n",
    "\n",
    "data_src.Destroy()\n",
    "\n",
    "# Fill the secondary reference labels\n",
    "tmp_flag = cls_ref_df['SecRefCode'] == 0\n",
    "cls_ref_df.loc[tmp_flag, 'SecRefCode'] = cls_ref_df.loc[tmp_flag, 'PriRefCode']\n",
    "\n",
    "# Get the classification labels\n",
    "cls_ref_df['ClsCode'] = cls_map[cls_ref_df['Line'].astype(int), cls_ref_df['Sample'].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_points = OrderedDict()\n",
    "\n",
    "# Randomly select several pixels with correct cropland classification and \n",
    "# several with wrong cropland classification\n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(np.logical_and(cls_ref_df['ClsCode']==1, cls_ref_df['PriRefCode']==1))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))\n",
    "        \n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(np.logical_and(cls_ref_df['ClsCode']==1, cls_ref_df['PriRefCode']!=1))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))\n",
    "        \n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(np.logical_and(cls_ref_df['ClsCode']!=1, cls_ref_df['PriRefCode']==1))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))\n",
    "        \n",
    "n_rnd = 6\n",
    "idx_candidates = np.where(reduce(np.logical_and, (cls_ref_df['ClsCode']!=1, cls_ref_df['PriRefCode']!=1, cls_ref_df['ClsCode']==cls_ref_df['PriRefCode'])))[0]\n",
    "if n_rnd > len(idx_candidates):\n",
    "    n_rnd = len(idx_candidates)\n",
    "idx_rnd = np.random.choice(idx_candidates, size=n_rnd, replace=False)\n",
    "for i, ir in enumerate(idx_rnd):\n",
    "    img_points['Cls({0:d})-Ref({1:d})-Pts{2:02d}'.format(int(cls_ref_df.loc[ir, 'ClsCode']), int(cls_ref_df.loc[ir, 'PriRefCode']), i+1)] \\\n",
    "        = (int(cls_ref_df.loc[ir, 'Sample']), int(cls_ref_df.loc[ir, 'Line']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert image coordinates to geographic and projected coordinates\n",
    "geo_points = OrderedDict([(k, pixel2Geo(ts_ndvi_fused_file, img_points[k][0]+0.5, img_points[k][1]+0.5)) for k in img_points.keys()])\n",
    "proj_points = OrderedDict([(k, pixel2Proj(get_raster_meta_GDAL(ts_ndvi_fused_file)[\"GeoTransform\"], img_points[k][0]+0.5, img_points[k][1]+0.5)) for k in img_points.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series from stacked STARFM+Landsat and TIMESAT DL fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_ndvi_fused_data = { k:read_pixel_GDAL(ts_ndvi_fused_file, img_points[k][0], img_points[k][1]) for k in img_points.keys()}\n",
    "ts_ndvi_fused_doy = np.arange(len(ts_ndvi_fused_data[ts_ndvi_fused_data.keys()[0]]))+1\n",
    "# sort the data points according to doy\n",
    "sort_ind = np.argsort(ts_ndvi_fused_doy)\n",
    "ts_ndvi_fused_data = {k:ts_ndvi_fused_data[k][sort_ind] for k in ts_ndvi_fused_data.keys()}\n",
    "ts_ndvi_fused_doy = ts_ndvi_fused_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_ndvi_timesat_data = { k:read_pixel_GDAL(ts_ndvi_timesat_file, img_points[k][0], img_points[k][1]) for k in img_points.keys()}\n",
    "ts_ndvi_timesat_doy = np.arange(len(ts_ndvi_timesat_data[ts_ndvi_timesat_data.keys()[0]]))+1\n",
    "# sort the data points according to doy\n",
    "sort_ind = np.argsort(ts_ndvi_timesat_doy)\n",
    "ts_ndvi_timesat_data = {k:ts_ndvi_timesat_data[k][sort_ind] for k in ts_ndvi_timesat_data.keys()}\n",
    "ts_ndvi_timesat_doy = ts_ndvi_timesat_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_ndvi_fused_meta = get_raster_meta_GDAL(ts_ndvi_fused_file)\n",
    "# get the nodata value of the given image\n",
    "if ts_ndvi_fused_meta[\"NoDataValue\"] is None:\n",
    "    nodata = -9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Selected DOY for image visualization\n",
    "    * Around second peak: 242, 245\n",
    "    * Around the trough: 186, 192\n",
    "    * Last day in the year: 365, 365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series from STARFM fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# red_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-starfm/Vietnam/plndsr_250.126046.2015*.red.bin\")\n",
    "# nir_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-starfm/Vietnam/plndsr_250.126046.2015*.nir.bin\")\n",
    "# ndvi_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-starfm/Vietnam/plndsr_250.126046.2015*.ndvi.bin\")\n",
    "\n",
    "# fnames, red_ts_data = get_ts_from_imgs(red_imgfiles, img_points)\n",
    "# red_doy = np.array([int(imgf.split(\".\")[2][4:]) for imgf in fnames])\n",
    "# # sort the data points according to doy\n",
    "# sort_ind = np.argsort(red_doy)\n",
    "# red_ts_data = {k:red_ts_data[k][sort_ind] for k in red_ts_data.keys()}\n",
    "# red_doy = red_doy[sort_ind]\n",
    "\n",
    "# fnames, nir_ts_data = get_ts_from_imgs(nir_imgfiles, img_points)\n",
    "# nir_doy = np.array([int(imgf.split(\".\")[2][4:]) for imgf in fnames])\n",
    "# # sort the data points according to doy\n",
    "# sort_ind = np.argsort(nir_doy)\n",
    "# nir_ts_data = {k:nir_ts_data[k][sort_ind] for k in nir_ts_data.keys()}\n",
    "# nir_doy = nir_doy[sort_ind]\n",
    "\n",
    "# fnames, ndvi_ts_data = get_ts_from_imgs(ndvi_imgfiles, img_points)\n",
    "# ndvi_doy = np.array([int(imgf.split(\".\")[2][4:]) for imgf in fnames])\n",
    "# # sort the data points according to doy\n",
    "# sort_ind = np.argsort(ndvi_doy)\n",
    "# ndvi_ts_data = {k:ndvi_ts_data[k][sort_ind] for k in ndvi_ts_data.keys()}\n",
    "# ndvi_doy = ndvi_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markers = mpl.markers.MarkerStyle().markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_ts([red_doy, nir_doy], [red_ts_data, nir_ts_data], geo_points, \\\n",
    "#         style_list=['.r', '.b'], \\\n",
    "#         plot_kw_dict_list=[dict(label=\"Red\"), dict(label=\"NIR\")], \\\n",
    "#         use_plotly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_ts([np.arange(len(ts_ndvi_fused_data[ts_ndvi_fused_data.keys()[0]]))+1, ndvi_doy], [ts_ndvi_fused_data, ndvi_ts_data], geo_points, \\\n",
    "#         style_list=['.r', '.g'], \\\n",
    "#         plot_kw_dict_list=[dict(label=\"NDVI Predicted\"), dict(label=\"NDVI STARFM\")], \\\n",
    "#         use_plotly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series from TIMESAT SG fitting to STARFM+Landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitsg_ndvi_imgfiles = glob.glob(\"/projectnb/echidna/lidar/zhanli86/workspace/data/projects/kaiyu-adb-crop/vietnam-ts-sg/fitSG_NDVI_126046.2015[0-9][0-9][0-9]\")\n",
    "\n",
    "fnames, sg_ndvi_ts_data = get_ts_from_imgs(fitsg_ndvi_imgfiles, img_points)\n",
    "sg_ndvi_doy = np.array([int(imgf.split(\".\")[1][4:]) for imgf in fnames])\n",
    "# sort the data points according to doy\n",
    "sort_ind = np.argsort(sg_ndvi_doy)\n",
    "sg_ndvi_ts_data = {k:sg_ndvi_ts_data[k][sort_ind] for k in sg_ndvi_ts_data.keys()}\n",
    "sg_ndvi_doy = sg_ndvi_doy[sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ts([ts_ndvi_fused_doy, ts_ndvi_timesat_doy, sg_ndvi_doy], \\\n",
    "        [ts_ndvi_fused_data, ts_ndvi_timesat_data, sg_ndvi_ts_data], geo_points, \\\n",
    "        style_list=['.r', '-b', '-k'], \\\n",
    "        plot_kw_dict_list=[dict(label=\"NDVI Predicted (fused + LC8)\"), dict(label=\"NDVI TIMESAT Double Logistic\"), dict(label=\"NDVI TIMESAT SG\")], \\\n",
    "        use_plotly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
